{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ML_Lab03-Minimizing_Cost.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyOqk2cG94FGLZZxsoVu9SD1",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SeyoungYoo/DLforEveryone/blob/main/Season01/ML_Lab03_Minimizing_Cost.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j_vc15NL19b1",
        "outputId": "3a3b12dc-bd51-457b-afdc-389ec45ea9ff"
      },
      "source": [
        "pip install tensorflow==1.15.0"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow==1.15.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/92/2b/e3af15221da9ff323521565fa3324b0d7c7c5b1d7a8ca66984c8d59cb0ce/tensorflow-1.15.0-cp37-cp37m-manylinux2010_x86_64.whl (412.3MB)\n",
            "\u001b[K     |████████████████████████████████| 412.3MB 38kB/s \n",
            "\u001b[?25hRequirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0) (1.1.2)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0) (1.15.0)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0) (1.32.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0) (0.36.2)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0) (0.2.0)\n",
            "Collecting tensorboard<1.16.0,>=1.15.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1e/e9/d3d747a97f7188f48aa5eda486907f3b345cd409f0a0850468ba867db246/tensorboard-1.15.0-py3-none-any.whl (3.8MB)\n",
            "\u001b[K     |████████████████████████████████| 3.8MB 31.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0) (1.19.5)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0) (3.3.0)\n",
            "Collecting tensorflow-estimator==1.15.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/de/62/2ee9cd74c9fa2fa450877847ba560b260f5d0fb70ee0595203082dafcc9d/tensorflow_estimator-1.15.1-py2.py3-none-any.whl (503kB)\n",
            "\u001b[K     |████████████████████████████████| 512kB 21.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0) (1.1.0)\n",
            "Collecting gast==0.2.2\n",
            "  Downloading https://files.pythonhosted.org/packages/4e/35/11749bf99b2d4e3cceb4d55ca22590b0d7c2c62b9de38ac4a4a7f4687421/gast-0.2.2.tar.gz\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0) (3.12.4)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0) (0.10.0)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0) (0.8.1)\n",
            "Collecting keras-applications>=1.0.8\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/71/e3/19762fdfc62877ae9102edf6342d71b28fbfd9dea3d2f96a882ce099b03f/Keras_Applications-1.0.8-py3-none-any.whl (50kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 4.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0) (1.12.1)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.0) (54.1.2)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.0) (1.0.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.0) (3.3.4)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras-applications>=1.0.8->tensorflow==1.15.0) (2.10.0)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.0) (3.7.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.0) (3.4.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.0) (3.7.4.3)\n",
            "Building wheels for collected packages: gast\n",
            "  Building wheel for gast (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gast: filename=gast-0.2.2-cp37-none-any.whl size=7540 sha256=05e206fe281f2a2b135004010c78782179b72422b53f3d2ee4a5ae4878ad959d\n",
            "  Stored in directory: /root/.cache/pip/wheels/5c/2e/7e/a1d4d4fcebe6c381f378ce7743a3ced3699feb89bcfbdadadd\n",
            "Successfully built gast\n",
            "\u001b[31mERROR: tensorflow-probability 0.12.1 has requirement gast>=0.3.2, but you'll have gast 0.2.2 which is incompatible.\u001b[0m\n",
            "Installing collected packages: tensorboard, tensorflow-estimator, gast, keras-applications, tensorflow\n",
            "  Found existing installation: tensorboard 2.4.1\n",
            "    Uninstalling tensorboard-2.4.1:\n",
            "      Successfully uninstalled tensorboard-2.4.1\n",
            "  Found existing installation: tensorflow-estimator 2.4.0\n",
            "    Uninstalling tensorflow-estimator-2.4.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.4.0\n",
            "  Found existing installation: gast 0.3.3\n",
            "    Uninstalling gast-0.3.3:\n",
            "      Successfully uninstalled gast-0.3.3\n",
            "  Found existing installation: tensorflow 2.4.1\n",
            "    Uninstalling tensorflow-2.4.1:\n",
            "      Successfully uninstalled tensorflow-2.4.1\n",
            "Successfully installed gast-0.2.2 keras-applications-1.0.8 tensorboard-1.15.0 tensorflow-1.15.0 tensorflow-estimator-1.15.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kgC459sK4eC8"
      },
      "source": [
        "##**cost를 최소화하기**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZrrSPbA92CrL"
      },
      "source": [
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CncjROUh4me3"
      },
      "source": [
        "X = [1,2,3]\n",
        "Y = [1,2,3]"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UrPkaLpZ4viJ"
      },
      "source": [
        "W = tf.placeholder(tf.float32)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lRuuwuNi40FN"
      },
      "source": [
        "# Our hypothesis for linear model X * W\n",
        "hypothesis = X * W\n",
        "\n",
        "# cost/Loss Function\n",
        "cost = tf.reduce_mean(tf.square(hypothesis - Y))"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NnSu8Oyl5Mx1"
      },
      "source": [
        "# Launch the graph in a session.\n",
        "sess = tf.Session()\n",
        "\n",
        "# Initializes global variables in the graph.\n",
        "sess.run(tf.global_variables_initializer())"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z4_ralS-5aYk"
      },
      "source": [
        "# Variables for plotting cost function\n",
        "# 그래프를 실행시키면서 발생할 W, cost를 저장할 리스트\n",
        "W_val = []\n",
        "cost_val = []"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L86nCe3G5lpA"
      },
      "source": [
        "# -30~50 실행시키기\n",
        "for i in range(-30, 50):\n",
        "  feed_W = i * 0.1    # W는 -3~5 사이를 움직임.\n",
        "  curr_cost, curr_W = sess.run([cost, W], feed_dict = {W: feed_W})    # feed_dict로 W를 바꿔가면서 실행\n",
        "  # 실행하면서 발생한 W와 cost를 리스트에 저장하기\n",
        "  W_val.append(curr_W)\n",
        "  cost_val.append(curr_cost)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "p6ZXFjwl6Ywe",
        "outputId": "cc28bd85-c4a2-486f-c4b5-a404502aca22"
      },
      "source": [
        "# Show the cost fuction\n",
        "# 그래프 그리기\n",
        "plt.plot(W_val, cost_val)   # x축: W_val, y축: cost_val\n",
        "plt.show()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MSWnse7463uB"
      },
      "source": [
        "* W가 1일 때 cost가 가장 최소화된다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cBtIwJ287z0r"
      },
      "source": [
        "##**Gradient descent**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IC2RLVZH8UOT"
      },
      "source": [
        "* cost의 최소화: 미분을 이용하여 Gradient Descent \n",
        "* W -= learning_rate * derivative\n",
        "\n",
        "  ```\n",
        "  learning_rate = 0.1\n",
        "  gradient = tf.reduce_mean((W * X - Y) * X)\n",
        "  descent = W - learning_rate * gradient\n",
        "  update = W.assign(descent) \n",
        "  ```\n",
        "\n",
        "  * graph에서 update를 실행시키면 위의 알고리즘이 돌아간다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bX9rgZD_9DQl"
      },
      "source": [
        "###**cost 최소화하기2**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UPVQj0CF9HWv"
      },
      "source": [
        "* Gradient Descent 이용"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vD7DlHZB9V5j"
      },
      "source": [
        "import tensorflow as tf"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kh2wudBv9ZBe"
      },
      "source": [
        "x_data = [1,2,3]\n",
        "y_data = [1,2,3]"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ICRso_A_9cYG"
      },
      "source": [
        "W = tf.Variable(tf.random_normal([1]), name = 'weight')\n",
        "X = tf.placeholder(tf.float32)\n",
        "Y = tf.placeholder(tf.float32)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HabuITJK9lrr"
      },
      "source": [
        "# Our hypothesis for linear model X * W\n",
        "hypothesis = X * W"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ooIKNU_79q_G"
      },
      "source": [
        "# cost/Loss function\n",
        "cost = tf.reduce_mean(tf.square(hypothesis - Y))"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ebflrrio9wPr"
      },
      "source": [
        "# Minimize: Gradient Descent using derivative: W -= learning_rate * derivative\n",
        "learning_rate = 0.1\n",
        "gradient = tf.reduce_mean((W * X - Y) * X)\n",
        "descent = W - learning_rate * gradient\n",
        "update = W.assign(descent)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "buvAVN96-Wzx"
      },
      "source": [
        "# Launch the graph in a session.\n",
        "sess = tf.Session()\n",
        "\n",
        "# Initializes global variables in the graph.\n",
        "sess.run(tf.global_variables_initializer())"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O4D5H_22-kel",
        "outputId": "dee9a1e6-0974-4d1b-bb08-bbbecf9b73c4"
      },
      "source": [
        "for step in range(21):\n",
        "  sess.run(update, feed_dict = {X: x_data, Y: y_data})\n",
        "  print(step, sess.run(cost, feed_dict = {X: x_data, Y: y_data}), sess.run(W))"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 0.95181566 [0.54838014]\n",
            "1 0.27073872 [0.7591361]\n",
            "2 0.07701009 [0.87153924]\n",
            "3 0.021905119 [0.93148756]\n",
            "4 0.0062307864 [0.96346]\n",
            "5 0.0017723171 [0.980512]\n",
            "6 0.0005041205 [0.98960644]\n",
            "7 0.00014339463 [0.99445677]\n",
            "8 4.0787807e-05 [0.9970436]\n",
            "9 1.1601761e-05 [0.9984233]\n",
            "10 3.299878e-06 [0.9991591]\n",
            "11 9.385654e-07 [0.99955153]\n",
            "12 2.6702486e-07 [0.9997608]\n",
            "13 7.59267e-08 [0.99987245]\n",
            "14 2.1592422e-08 [0.999932]\n",
            "15 6.1287815e-09 [0.99996376]\n",
            "16 1.7404318e-09 [0.9999807]\n",
            "17 4.974332e-10 [0.9999897]\n",
            "18 1.4032746e-10 [0.9999945]\n",
            "19 4.0156323e-11 [0.9999971]\n",
            "20 1.1581847e-11 [0.99999845]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nt3x0ze4_q-a"
      },
      "source": [
        "**Gradient Descent Magic**\n",
        "* cost를 일일이 미분하지 않아도 자동으로 처리해주는 방법\n",
        "\n",
        "  ```\n",
        "  optimizer = tf.train.GradientDescentOptimizer(learning_rate = 0.1)\n",
        "  train = optimizer.minimize(cost)\n",
        "  ```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "azEnvC71AOkh"
      },
      "source": [
        "###**W=5일때**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JhktP8L4AhYP"
      },
      "source": [
        "* W를 터무니없는 값을 주고 시작했을 때 잘 작동하는지를 알아보기 위함"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0SVUEGin-7uA"
      },
      "source": [
        "import tensorflow as tf"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0RKn80NmAm7q"
      },
      "source": [
        "# tf Graph Input\n",
        "X = [1,2,3]\n",
        "Y = [1,2,3]"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EuioxKo3AqPI"
      },
      "source": [
        "# Set wrong model weights\n",
        "W = tf.Variable(5.0)"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FWAD5_8wAucb"
      },
      "source": [
        "# Linear model\n",
        "hypothesis = X * W\n",
        "# cost/Loss function\n",
        "cost = tf.reduce_mean(tf.square(hypothesis - Y))"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BmLJQ-6pA_hf"
      },
      "source": [
        "# Minimize: Gradient Descent Magic\n",
        "optimizer = tf.train.GradientDescentOptimizer(learning_rate = 0.1)\n",
        "train = optimizer.minimize(cost)"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_qAPvQeeBIzQ"
      },
      "source": [
        "# Launch the graph in a session\n",
        "sess = tf.Session()\n",
        "# Initializes global variables in the grpah.\n",
        "sess.run(tf.global_variables_initializer())"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nhEsFZl6BSJJ",
        "outputId": "7bef6f52-22c1-4821-b864-c7b1dc4cb642"
      },
      "source": [
        "for step in range(10):\n",
        "  print(step, sess.run(W))\n",
        "  sess.run(train)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 5.0\n",
            "1 1.2666664\n",
            "2 1.0177778\n",
            "3 1.0011852\n",
            "4 1.000079\n",
            "5 1.0000052\n",
            "6 1.0000004\n",
            "7 1.0\n",
            "8 1.0\n",
            "9 1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MsemoQJFBhHa"
      },
      "source": [
        "* optimizer가 제대로 동작하는 것을 확인할 수 있다.\n",
        "  * W가 1.0으로 수렴하는 것을 통해 알 수 있음."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qrSbpiYBC6TU"
      },
      "source": [
        "##**Optional: compute_gradient and apply_gradient**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NnANpaVMBY-Z"
      },
      "source": [
        "import tensorflow as tf"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dNgb9kLwDJ8r"
      },
      "source": [
        "X = [1,2,3]\n",
        "Y = [1,2,3]"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "khOyXaXDDL84"
      },
      "source": [
        "# Set wrong model weights\n",
        "W = tf.Variable(5.)"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z4UIw5jvDQPF"
      },
      "source": [
        "# Linear model\n",
        "hypothesis = X * W\n",
        "\n",
        "# Manual gradient\n",
        "gradient = tf.reduce_mean((W * X - Y) * X) * 2   # 손으로 계산한 gradient\n",
        "\n",
        "# cost/Loss Function\n",
        "cost = tf.reduce_mean(tf.square(hypothesis - Y))\n",
        "optimizer = tf.train.GradientDescentOptimizer(learning_rate = 0.01)"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N4qbU7OoD0qf"
      },
      "source": [
        "# Get gradients\n",
        "gvs = optimizer.compute_gradients(cost, [W])\n",
        "\n",
        "# Apply gradients\n",
        "apply_gradients = optimizer.apply_gradients(gvs)"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E51xThnOEAvw"
      },
      "source": [
        "# Launch the graph in a session.\n",
        "sess = tf.Session()\n",
        "sess.run(tf.global_variables_initializer())"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-odNi_y1F8-1",
        "outputId": "ad56e500-898a-4a5d-fbf9-2b3bb698ef6c"
      },
      "source": [
        "for step in range(100):\n",
        "  print(step, sess.run([gradient, W, gvs]))\n",
        "  sess.run(apply_gradients)"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 [37.333332, 5.0, [(37.333336, 5.0)]]\n",
            "1 [33.84889, 4.6266665, [(33.84889, 4.6266665)]]\n",
            "2 [30.689657, 4.2881775, [(30.689657, 4.2881775)]]\n",
            "3 [27.825287, 3.9812808, [(27.825287, 3.9812808)]]\n",
            "4 [25.228262, 3.703028, [(25.228262, 3.703028)]]\n",
            "5 [22.873621, 3.4507453, [(22.873623, 3.4507453)]]\n",
            "6 [20.738752, 3.2220092, [(20.73875, 3.2220092)]]\n",
            "7 [18.803137, 3.0146217, [(18.803137, 3.0146217)]]\n",
            "8 [17.048176, 2.8265903, [(17.048176, 2.8265903)]]\n",
            "9 [15.457013, 2.6561086, [(15.457014, 2.6561086)]]\n",
            "10 [14.014359, 2.5015385, [(14.01436, 2.5015385)]]\n",
            "11 [12.706352, 2.361395, [(12.706352, 2.361395)]]\n",
            "12 [11.520427, 2.2343314, [(11.520427, 2.2343314)]]\n",
            "13 [10.445186, 2.119127, [(10.445185, 2.119127)]]\n",
            "14 [9.470302, 2.0146751, [(9.470302, 2.0146751)]]\n",
            "15 [8.586407, 1.9199722, [(8.586407, 1.9199722)]]\n",
            "16 [7.785009, 1.8341081, [(7.785009, 1.8341081)]]\n",
            "17 [7.0584083, 1.756258, [(7.0584083, 1.756258)]]\n",
            "18 [6.399624, 1.685674, [(6.399624, 1.685674)]]\n",
            "19 [5.8023257, 1.6216778, [(5.8023252, 1.6216778)]]\n",
            "20 [5.260776, 1.5636545, [(5.260776, 1.5636545)]]\n",
            "21 [4.7697697, 1.5110468, [(4.7697697, 1.5110468)]]\n",
            "22 [4.324591, 1.4633491, [(4.324591, 1.4633491)]]\n",
            "23 [3.9209633, 1.4201032, [(3.9209635, 1.4201032)]]\n",
            "24 [3.5550067, 1.3808936, [(3.5550067, 1.3808936)]]\n",
            "25 [3.2232056, 1.3453435, [(3.2232056, 1.3453435)]]\n",
            "26 [2.9223735, 1.3131114, [(2.9223735, 1.3131114)]]\n",
            "27 [2.6496189, 1.2838877, [(2.6496186, 1.2838877)]]\n",
            "28 [2.4023216, 1.2573916, [(2.4023216, 1.2573916)]]\n",
            "29 [2.178105, 1.2333684, [(2.178105, 1.2333684)]]\n",
            "30 [1.9748148, 1.2115873, [(1.9748147, 1.2115873)]]\n",
            "31 [1.7904993, 1.1918392, [(1.7904994, 1.1918392)]]\n",
            "32 [1.623386, 1.1739342, [(1.6233861, 1.1739342)]]\n",
            "33 [1.4718695, 1.1577003, [(1.4718695, 1.1577003)]]\n",
            "34 [1.3344955, 1.1429816, [(1.3344957, 1.1429816)]]\n",
            "35 [1.2099417, 1.1296366, [(1.2099419, 1.1296366)]]\n",
            "36 [1.0970144, 1.1175373, [(1.0970144, 1.1175373)]]\n",
            "37 [0.9946267, 1.1065671, [(0.9946267, 1.1065671)]]\n",
            "38 [0.90179497, 1.0966209, [(0.901795, 1.0966209)]]\n",
            "39 [0.8176275, 1.087603, [(0.81762755, 1.087603)]]\n",
            "40 [0.7413151, 1.0794266, [(0.7413151, 1.0794266)]]\n",
            "41 [0.67212623, 1.0720135, [(0.67212623, 1.0720135)]]\n",
            "42 [0.609394, 1.0652922, [(0.609394, 1.0652922)]]\n",
            "43 [0.5525169, 1.0591983, [(0.5525169, 1.0591983)]]\n",
            "44 [0.50094914, 1.0536731, [(0.50094914, 1.0536731)]]\n",
            "45 [0.45419374, 1.0486636, [(0.45419377, 1.0486636)]]\n",
            "46 [0.41180158, 1.0441216, [(0.41180158, 1.0441216)]]\n",
            "47 [0.37336722, 1.0400037, [(0.37336725, 1.0400037)]]\n",
            "48 [0.33851996, 1.03627, [(0.33852, 1.03627)]]\n",
            "49 [0.30692515, 1.0328848, [(0.30692515, 1.0328848)]]\n",
            "50 [0.27827826, 1.0298156, [(0.2782783, 1.0298156)]]\n",
            "51 [0.25230527, 1.0270327, [(0.25230527, 1.0270327)]]\n",
            "52 [0.2287569, 1.0245097, [(0.2287569, 1.0245097)]]\n",
            "53 [0.20740573, 1.022222, [(0.20740573, 1.022222)]]\n",
            "54 [0.18804836, 1.020148, [(0.18804836, 1.020148)]]\n",
            "55 [0.17049654, 1.0182675, [(0.17049655, 1.0182675)]]\n",
            "56 [0.15458433, 1.0165626, [(0.15458433, 1.0165626)]]\n",
            "57 [0.14015675, 1.0150168, [(0.14015675, 1.0150168)]]\n",
            "58 [0.12707591, 1.0136153, [(0.12707591, 1.0136153)]]\n",
            "59 [0.11521538, 1.0123445, [(0.11521538, 1.0123445)]]\n",
            "60 [0.10446167, 1.0111923, [(0.10446167, 1.0111923)]]\n",
            "61 [0.09471202, 1.0101477, [(0.09471202, 1.0101477)]]\n",
            "62 [0.08587202, 1.0092006, [(0.08587202, 1.0092006)]]\n",
            "63 [0.07785805, 1.0083419, [(0.07785805, 1.0083419)]]\n",
            "64 [0.07059129, 1.0075634, [(0.07059129, 1.0075634)]]\n",
            "65 [0.06400236, 1.0068574, [(0.06400236, 1.0068574)]]\n",
            "66 [0.05802846, 1.0062174, [(0.05802846, 1.0062174)]]\n",
            "67 [0.052612226, 1.005637, [(0.052612226, 1.005637)]]\n",
            "68 [0.047702473, 1.005111, [(0.047702473, 1.005111)]]\n",
            "69 [0.043249767, 1.0046339, [(0.043249767, 1.0046339)]]\n",
            "70 [0.03921318, 1.0042014, [(0.03921318, 1.0042014)]]\n",
            "71 [0.035553534, 1.0038093, [(0.035553537, 1.0038093)]]\n",
            "72 [0.032236177, 1.0034539, [(0.03223618, 1.0034539)]]\n",
            "73 [0.029227654, 1.0031315, [(0.029227655, 1.0031315)]]\n",
            "74 [0.02649951, 1.0028392, [(0.02649951, 1.0028392)]]\n",
            "75 [0.024025917, 1.0025742, [(0.024025917, 1.0025742)]]\n",
            "76 [0.021783749, 1.002334, [(0.02178375, 1.002334)]]\n",
            "77 [0.01975123, 1.0021162, [(0.019751232, 1.0021162)]]\n",
            "78 [0.017907381, 1.0019187, [(0.017907381, 1.0019187)]]\n",
            "79 [0.016236702, 1.0017396, [(0.016236704, 1.0017396)]]\n",
            "80 [0.014720838, 1.0015773, [(0.014720838, 1.0015773)]]\n",
            "81 [0.01334699, 1.00143, [(0.013346991, 1.00143)]]\n",
            "82 [0.012100856, 1.0012965, [(0.012100856, 1.0012965)]]\n",
            "83 [0.010971785, 1.0011755, [(0.010971785, 1.0011755)]]\n",
            "84 [0.0099481745, 1.0010659, [(0.0099481745, 1.0010659)]]\n",
            "85 [0.009018898, 1.0009663, [(0.009018898, 1.0009663)]]\n",
            "86 [0.008176883, 1.0008761, [(0.008176884, 1.0008761)]]\n",
            "87 [0.007413149, 1.0007943, [(0.007413149, 1.0007943)]]\n",
            "88 [0.006721576, 1.0007201, [(0.006721576, 1.0007201)]]\n",
            "89 [0.0060940585, 1.0006529, [(0.0060940585, 1.0006529)]]\n",
            "90 [0.005525271, 1.000592, [(0.0055252714, 1.000592)]]\n",
            "91 [0.0050098896, 1.0005368, [(0.0050098896, 1.0005368)]]\n",
            "92 [0.004542589, 1.0004867, [(0.004542589, 1.0004867)]]\n",
            "93 [0.0041189194, 1.0004413, [(0.0041189194, 1.0004413)]]\n",
            "94 [0.0037339528, 1.0004001, [(0.003733953, 1.0004001)]]\n",
            "95 [0.0033854644, 1.0003628, [(0.0033854644, 1.0003628)]]\n",
            "96 [0.0030694802, 1.0003289, [(0.0030694804, 1.0003289)]]\n",
            "97 [0.0027837753, 1.0002983, [(0.0027837753, 1.0002983)]]\n",
            "98 [0.0025234222, 1.0002704, [(0.0025234222, 1.0002704)]]\n",
            "99 [0.0022875469, 1.0002451, [(0.0022875469, 1.0002451)]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9ujVwGsLG_2H"
      },
      "source": [
        "* 손으로 계산한 gradient(gradient)와 컴퓨터가 자동으로 계산한 gradient(gvs)는 유사하다."
      ]
    }
  ]
}