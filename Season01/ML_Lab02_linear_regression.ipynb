{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ML_Lab02-linear_regression.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNG0SC9a4q5+f5O3T50vTvO",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SeyoungYoo/DLforEveryone/blob/main/Season01/ML_Lab02_linear_regression.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UOTs-jJtYOF9"
      },
      "source": [
        "1.15.0 버전 설치\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lp0yaKKkQkl6",
        "outputId": "2aa39fde-8c32-419a-d3b1-008dc67a82b4"
      },
      "source": [
        "pip install tensorflow==1.15.0"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow==1.15.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/92/2b/e3af15221da9ff323521565fa3324b0d7c7c5b1d7a8ca66984c8d59cb0ce/tensorflow-1.15.0-cp37-cp37m-manylinux2010_x86_64.whl (412.3MB)\n",
            "\u001b[K     |████████████████████████████████| 412.3MB 30kB/s \n",
            "\u001b[?25hCollecting tensorflow-estimator==1.15.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/de/62/2ee9cd74c9fa2fa450877847ba560b260f5d0fb70ee0595203082dafcc9d/tensorflow_estimator-1.15.1-py2.py3-none-any.whl (503kB)\n",
            "\u001b[K     |████████████████████████████████| 512kB 36.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0) (3.3.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0) (1.15.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0) (1.1.2)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0) (1.12.1)\n",
            "Collecting keras-applications>=1.0.8\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/71/e3/19762fdfc62877ae9102edf6342d71b28fbfd9dea3d2f96a882ce099b03f/Keras_Applications-1.0.8-py3-none-any.whl (50kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 5.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0) (0.8.1)\n",
            "Collecting gast==0.2.2\n",
            "  Downloading https://files.pythonhosted.org/packages/4e/35/11749bf99b2d4e3cceb4d55ca22590b0d7c2c62b9de38ac4a4a7f4687421/gast-0.2.2.tar.gz\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0) (1.32.0)\n",
            "Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0) (1.19.5)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0) (0.36.2)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0) (0.10.0)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0) (3.12.4)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0) (1.1.0)\n",
            "Collecting tensorboard<1.16.0,>=1.15.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1e/e9/d3d747a97f7188f48aa5eda486907f3b345cd409f0a0850468ba867db246/tensorboard-1.15.0-py3-none-any.whl (3.8MB)\n",
            "\u001b[K     |████████████████████████████████| 3.8MB 34.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0) (0.2.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras-applications>=1.0.8->tensorflow==1.15.0) (2.10.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from protobuf>=3.6.1->tensorflow==1.15.0) (54.1.2)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.0) (1.0.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.0) (3.3.4)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.0) (3.7.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.0) (3.4.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.0) (3.7.4.3)\n",
            "Building wheels for collected packages: gast\n",
            "  Building wheel for gast (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gast: filename=gast-0.2.2-cp37-none-any.whl size=7540 sha256=cdf346ae0656ad213699cd71907a24744be9e1e1323c8a76c2610c48ea747d38\n",
            "  Stored in directory: /root/.cache/pip/wheels/5c/2e/7e/a1d4d4fcebe6c381f378ce7743a3ced3699feb89bcfbdadadd\n",
            "Successfully built gast\n",
            "\u001b[31mERROR: tensorflow-probability 0.12.1 has requirement gast>=0.3.2, but you'll have gast 0.2.2 which is incompatible.\u001b[0m\n",
            "Installing collected packages: tensorflow-estimator, keras-applications, gast, tensorboard, tensorflow\n",
            "  Found existing installation: tensorflow-estimator 2.4.0\n",
            "    Uninstalling tensorflow-estimator-2.4.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.4.0\n",
            "  Found existing installation: gast 0.3.3\n",
            "    Uninstalling gast-0.3.3:\n",
            "      Successfully uninstalled gast-0.3.3\n",
            "  Found existing installation: tensorboard 2.4.1\n",
            "    Uninstalling tensorboard-2.4.1:\n",
            "      Successfully uninstalled tensorboard-2.4.1\n",
            "  Found existing installation: tensorflow 2.4.1\n",
            "    Uninstalling tensorflow-2.4.1:\n",
            "      Successfully uninstalled tensorflow-2.4.1\n",
            "Successfully installed gast-0.2.2 keras-applications-1.0.8 tensorboard-1.15.0 tensorflow-1.15.0 tensorflow-estimator-1.15.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pnaVH3fnQzp7"
      },
      "source": [
        "import tensorflow as tf"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "bcOJOgNbXYZD",
        "outputId": "2b13e172-20f8-492a-9f3b-724910947fa1"
      },
      "source": [
        "tf.__version__"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'1.15.0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vi1WMenjSoI5"
      },
      "source": [
        "##**Build graph using TF operations**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JM6y2QxIRXcS"
      },
      "source": [
        "# X and Y data\n",
        "x_train = [1,2,3]\n",
        "y_train = [1,2,3]\n",
        "\n",
        "W = tf.Variable(tf.random_normal([1]), name='weight')\n",
        "b = tf.Variable(tf.random_normal([1]), name='bias')\n",
        "\n",
        "# Our hypothesis XW+b\n",
        "hypothesis = x_train * W + b\n",
        "\n",
        "# cost/Loss function\n",
        "cost = tf.reduce_mean(tf.square(hypothesis - y_train))\n",
        "\n",
        "# Minimize\n",
        "optimizer = tf.train.GradientDescentOptimizer(learning_rate = 0.01)\n",
        "train = optimizer.minimize(cost)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X90YqP9BYZD7"
      },
      "source": [
        "* W와 b를 정의하기 위해 Variable로 선언해준다.\n",
        "  * Variable: tf 실행 시 tf 자체적으로 변경시키는 값\n",
        "  * Variable을 만들기 위해서는 shape이 어떻게 되는지 정의(1)하고 현재는 W와 b의 값을 모르기 때문에 random한 값으로 주게 된다.  \n",
        "* hypothesis를 W와 b를 가지고 정의한다.\n",
        "  * 여기서는 간단하게 x_train * W + b로 정의한다.\n",
        "* cost function을 정의해준다.\n",
        "  * tf의 함수를 활용(tf.reduce_mean: 평균구하기, tf.square: 제곱) \n",
        "* cost를 최소화하기\n",
        "  * GradientDescent 사용하여 optimizer 정의\n",
        "  * optimizer를 사용하여 cost를 최소화"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vSc22fTKa3cl"
      },
      "source": [
        "##**Run/Update graph and get results**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VBAUkWDqa8OO"
      },
      "source": [
        "* 그래프가 구현되었으면\n",
        "  * 그래프의 session을 만들고\n",
        "  * tf의 W, b 변수를 사용하기 위해 global_variables_initializer()를 실행시켜준다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nA19hNpIbfZ1",
        "outputId": "666d8550-69ed-49a0-fad3-595689212328"
      },
      "source": [
        "# Launch the graph in a session.\n",
        "sess = tf.Session()\n",
        "# Initializes global variables in the graph.\n",
        "sess.run(tf.global_variables_initializer())\n",
        "\n",
        "# Fit the line\n",
        "for step in range(3001):\n",
        "  sess.run(train)\n",
        "  if step % 20 == 0:\n",
        "    print(step, sess.run(cost), sess.run(W), sess.run(b))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 3.821046 [0.5873707] [2.7507553]\n",
            "20 0.81322724 [0.03364371] [2.3693638]\n",
            "40 0.7144947 [0.02448702] [2.234006]\n",
            "60 0.6486972 [0.06513621] [2.1267302]\n",
            "80 0.58915544 [0.10857649] [2.0265644]\n",
            "100 0.53508025 [0.15042298] [1.9313024]\n",
            "120 0.4859685 [0.19034548] [1.8405364]\n",
            "140 0.4413643 [0.22839591] [1.7540375]\n",
            "160 0.40085423 [0.26465833] [1.6716045]\n",
            "180 0.36406216 [0.29921666] [1.5930451]\n",
            "200 0.33064717 [0.3321509] [1.518178]\n",
            "220 0.30029905 [0.3635373] [1.4468292]\n",
            "240 0.27273637 [0.39344874] [1.3788335]\n",
            "260 0.24770355 [0.42195448] [1.3140334]\n",
            "280 0.22496831 [0.44912043] [1.2522787]\n",
            "300 0.20431988 [0.47500974] [1.1934264]\n",
            "320 0.18556666 [0.49968228] [1.1373398]\n",
            "340 0.16853458 [0.5231953] [1.083889]\n",
            "360 0.15306585 [0.54560345] [1.0329503]\n",
            "380 0.13901679 [0.5669584] [0.9844054]\n",
            "400 0.12625733 [0.5873097] [0.93814194]\n",
            "420 0.114668906 [0.6067047] [0.89405274]\n",
            "440 0.104144074 [0.6251882] [0.8520354]\n",
            "460 0.09458531 [0.642803] [0.8119928]\n",
            "480 0.08590392 [0.6595899] [0.77383214]\n",
            "500 0.07801933 [0.6755879] [0.73746496]\n",
            "520 0.07085839 [0.69083405] [0.70280683]\n",
            "540 0.06435477 [0.7053637] [0.6697775]\n",
            "560 0.05844799 [0.71921057] [0.63830036]\n",
            "580 0.05308345 [0.73240656] [0.6083027]\n",
            "600 0.048211213 [0.7449826] [0.5797146]\n",
            "620 0.043786187 [0.7569674] [0.55247015]\n",
            "640 0.039767306 [0.76838917] [0.526506]\n",
            "660 0.03611728 [0.779274] [0.5017621]\n",
            "680 0.032802317 [0.7896473] [0.47818118]\n",
            "700 0.029791577 [0.7995331] [0.45570844]\n",
            "720 0.027057169 [0.80895436] [0.43429178]\n",
            "740 0.024573775 [0.81793284] [0.41388163]\n",
            "760 0.02231828 [0.8264894] [0.39443064]\n",
            "780 0.020269811 [0.83464366] [0.3758938]\n",
            "800 0.018409377 [0.8424148] [0.35822824]\n",
            "820 0.016719675 [0.84982073] [0.3413928]\n",
            "840 0.015185091 [0.8568785] [0.32534862]\n",
            "860 0.013791342 [0.8636047] [0.3100585]\n",
            "880 0.012525518 [0.8700148] [0.29548696]\n",
            "900 0.011375885 [0.87612355] [0.28160024]\n",
            "920 0.010331772 [0.8819453] [0.26836607]\n",
            "940 0.009383469 [0.88749343] [0.2557539]\n",
            "960 0.008522234 [0.89278084] [0.24373445]\n",
            "980 0.0077400305 [0.8978197] [0.23227982]\n",
            "1000 0.007029613 [0.9026218] [0.22136353]\n",
            "1020 0.006384405 [0.9071982] [0.21096028]\n",
            "1040 0.0057984255 [0.9115595] [0.20104593]\n",
            "1060 0.0052662273 [0.9157159] [0.19159752]\n",
            "1080 0.004782874 [0.91967696] [0.18259318]\n",
            "1100 0.0043438794 [0.92345184] [0.17401198]\n",
            "1120 0.003945181 [0.9270493] [0.16583404]\n",
            "1140 0.003583077 [0.9304777] [0.15804051]\n",
            "1160 0.0032542006 [0.933745] [0.15061319]\n",
            "1180 0.0029555196 [0.9368588] [0.1435349]\n",
            "1200 0.002684252 [0.93982613] [0.13678935]\n",
            "1220 0.002437882 [0.9426541] [0.13036074]\n",
            "1240 0.002214131 [0.9453491] [0.12423427]\n",
            "1260 0.0020108966 [0.9479176] [0.1183957]\n",
            "1280 0.0018263339 [0.95036525] [0.11283153]\n",
            "1300 0.0016587018 [0.9526979] [0.10752884]\n",
            "1320 0.001506459 [0.9549209] [0.10247536]\n",
            "1340 0.0013681947 [0.9570394] [0.09765942]\n",
            "1360 0.0012426174 [0.9590583] [0.09306982]\n",
            "1380 0.0011285635 [0.9609825] [0.08869591]\n",
            "1400 0.0010249832 [0.9628162] [0.08452753]\n",
            "1420 0.0009309086 [0.9645637] [0.08055506]\n",
            "1440 0.0008454576 [0.9662291] [0.07676926]\n",
            "1460 0.0007678638 [0.9678161] [0.07316141]\n",
            "1480 0.00069738744 [0.9693286] [0.06972315]\n",
            "1500 0.0006333757 [0.9707701] [0.06644645]\n",
            "1520 0.00057524355 [0.9721438] [0.06332368]\n",
            "1540 0.0005224451 [0.9734529] [0.0603477]\n",
            "1560 0.00047449153 [0.97470057] [0.05751158]\n",
            "1580 0.00043094205 [0.97588956] [0.05480874]\n",
            "1600 0.00039138924 [0.97702265] [0.05223295]\n",
            "1620 0.00035546627 [0.97810245] [0.04977821]\n",
            "1640 0.00032284154 [0.9791316] [0.04743885]\n",
            "1660 0.0002932079 [0.98011243] [0.04520933]\n",
            "1680 0.00026629653 [0.98104703] [0.04308463]\n",
            "1700 0.00024185407 [0.9819377] [0.04105982]\n",
            "1720 0.0002196558 [0.9827866] [0.03913016]\n",
            "1740 0.00019949615 [0.98359555] [0.03729117]\n",
            "1760 0.00018118258 [0.98436654] [0.0355386]\n",
            "1780 0.00016455463 [0.9851013] [0.03386841]\n",
            "1800 0.00014945067 [0.98580146] [0.03227669]\n",
            "1820 0.00013573372 [0.98646873] [0.03075978]\n",
            "1840 0.00012327527 [0.9871046] [0.0293142]\n",
            "1860 0.00011196182 [0.98771065] [0.02793655]\n",
            "1880 0.00010168373 [0.9882882] [0.02662365]\n",
            "1900 9.23519e-05 [0.98883855] [0.02537244]\n",
            "1920 8.387471e-05 [0.989363] [0.02418008]\n",
            "1940 7.6178e-05 [0.9898631] [0.02304374]\n",
            "1960 6.9185415e-05 [0.99033946] [0.02196072]\n",
            "1980 6.283486e-05 [0.99079347] [0.02092862]\n",
            "2000 5.706686e-05 [0.9912262] [0.01994504]\n",
            "2020 5.1829964e-05 [0.99163854] [0.01900767]\n",
            "2040 4.7073034e-05 [0.99203146] [0.01811436]\n",
            "2060 4.2751723e-05 [0.992406] [0.01726304]\n",
            "2080 3.8827082e-05 [0.99276286] [0.01645172]\n",
            "2100 3.5264045e-05 [0.99310297] [0.01567856]\n",
            "2120 3.202753e-05 [0.99342716] [0.01494171]\n",
            "2140 2.9087778e-05 [0.99373597] [0.0142395]\n",
            "2160 2.641834e-05 [0.99403036] [0.01357033]\n",
            "2180 2.3993309e-05 [0.9943109] [0.01293258]\n",
            "2200 2.1791517e-05 [0.99457824] [0.01232483]\n",
            "2220 1.979099e-05 [0.99483305] [0.01174563]\n",
            "2240 1.7974577e-05 [0.9950759] [0.01119365]\n",
            "2260 1.6325137e-05 [0.9953073] [0.01066759]\n",
            "2280 1.4826429e-05 [0.99552786] [0.01016625]\n",
            "2300 1.346603e-05 [0.995738] [0.00968848]\n",
            "2320 1.2229713e-05 [0.9959383] [0.00923316]\n",
            "2340 1.1107306e-05 [0.9961292] [0.00879925]\n",
            "2360 1.0088274e-05 [0.99631107] [0.00838572]\n",
            "2380 9.162211e-06 [0.99648446] [0.00799164]\n",
            "2400 8.321323e-06 [0.9966497] [0.0076161]\n",
            "2420 7.5573116e-06 [0.99680716] [0.00725815]\n",
            "2440 6.863835e-06 [0.9969572] [0.00691703]\n",
            "2460 6.233571e-06 [0.9971002] [0.00659195]\n",
            "2480 5.661657e-06 [0.9972365] [0.00628216]\n",
            "2500 5.142005e-06 [0.99736637] [0.00598692]\n",
            "2520 4.669933e-06 [0.99749005] [0.00570557]\n",
            "2540 4.2416136e-06 [0.99760807] [0.00543744]\n",
            "2560 3.8520734e-06 [0.9977204] [0.00518191]\n",
            "2580 3.4984757e-06 [0.9978276] [0.00493839]\n",
            "2600 3.1772727e-06 [0.9979297] [0.00470631]\n",
            "2620 2.8857157e-06 [0.99802697] [0.00448515]\n",
            "2640 2.6209439e-06 [0.99811965] [0.00427438]\n",
            "2660 2.3804982e-06 [0.998208] [0.00407353]\n",
            "2680 2.161985e-06 [0.9982922] [0.00388213]\n",
            "2700 1.9635975e-06 [0.9983725] [0.00369969]\n",
            "2720 1.7833974e-06 [0.99844897] [0.00352583]\n",
            "2740 1.6197524e-06 [0.99852186] [0.00336013]\n",
            "2760 1.4711795e-06 [0.9985913] [0.00320224]\n",
            "2780 1.3360601e-06 [0.99865746] [0.00305175]\n",
            "2800 1.2135148e-06 [0.9987205] [0.00290838]\n",
            "2820 1.1022224e-06 [0.99878067] [0.00277171]\n",
            "2840 1.0010039e-06 [0.99883795] [0.00264149]\n",
            "2860 9.089911e-07 [0.9988926] [0.00251736]\n",
            "2880 8.2580056e-07 [0.99894464] [0.00239907]\n",
            "2900 7.4993403e-07 [0.99899423] [0.00228635]\n",
            "2920 6.811052e-07 [0.9990415] [0.00217891]\n",
            "2940 6.185092e-07 [0.99908644] [0.00207653]\n",
            "2960 5.618765e-07 [0.99912935] [0.00197897]\n",
            "2980 5.102025e-07 [0.99917036] [0.00188601]\n",
            "3000 4.6346804e-07 [0.9992092] [0.00179741]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ozmtMgK4dbMq"
      },
      "source": [
        "학습 시킬수록 예상했던 바와 같이 W는 1에, b는 0에 가까워진다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hYhMGtbXdkqO"
      },
      "source": [
        "##**Placeholder를 이용하여 Linear Regression 실행시키기**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A_JdsGY3b1e_",
        "outputId": "563e07e9-d06d-4023-f88b-7615b15174be"
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "W = tf.Variable(tf.random_normal([1]), name='weight')\n",
        "b = tf.Variable(tf.random_normal([1]), name='bias')\n",
        "X = tf.placeholder(tf.float32, shape=[None])\n",
        "Y = tf.placeholder(tf.float32, shape=[None])\n",
        "\n",
        "\n",
        "# Our hypothesis XW+b\n",
        "hypothesis = X * W + b\n",
        "# cost/Loss function\n",
        "cost = tf.reduce_mean(tf.square(hypothesis - Y))\n",
        "# Minimize\n",
        "optimizer = tf.train.GradientDescentOptimizer(learning_rate = 0.01)\n",
        "train = optimizer.minimize(cost)\n",
        "\n",
        "# Launch the graph in a session.\n",
        "sess = tf.Session()\n",
        "# Initializes global variables in the graph.\n",
        "sess.run(tf.global_variables_initializer())\n",
        "\n",
        "# Fit the line with new training data\n",
        "for step in range(2001):\n",
        "  cost_val, W_val, b_val, _ = sess.run([cost, W, b, train],\n",
        "                                       feed_dict={X:[1,2,3,4,5], Y:[2.1,3.1,4.1,5.1,6.1]})\n",
        "  if step % 20 == 0:\n",
        "    print(step, cost_val, W_val, b_val)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 24.793533 [0.24541377] [-0.29700923]\n",
            "20 0.19532847 [1.2808075] [0.06758131]\n",
            "40 0.17014423 [1.2668706] [0.13642865]\n",
            "60 0.14858821 [1.249413] [0.19953921]\n",
            "80 0.12976313 [1.233079] [0.2585111]\n",
            "100 0.113323174 [1.2178143] [0.31362084]\n",
            "120 0.09896591 [1.2035495] [0.36512142]\n",
            "140 0.086427726 [1.1902189] [0.41324922]\n",
            "160 0.075477935 [1.1777613] [0.4582251]\n",
            "180 0.06591546 [1.1661196] [0.5002555]\n",
            "200 0.057564486 [1.1552402] [0.5395332]\n",
            "220 0.05027142 [1.1450734] [0.57623875]\n",
            "240 0.043902446 [1.1355726] [0.61054033]\n",
            "260 0.038340323 [1.1266937] [0.6425953]\n",
            "280 0.0334829 [1.1183964] [0.67255116]\n",
            "300 0.029240897 [1.1106426] [0.7005451]\n",
            "320 0.02553628 [1.1033965] [0.7267057]\n",
            "340 0.022301015 [1.096625] [0.751153]\n",
            "360 0.019475635 [1.0902969] [0.7739994]\n",
            "380 0.017008219 [1.0843834] [0.79534936]\n",
            "400 0.014853416 [1.0788571] [0.81530106]\n",
            "420 0.012971602 [1.0736927] [0.83394617]\n",
            "440 0.011328216 [1.0688665] [0.85137016]\n",
            "460 0.009893021 [1.0643564] [0.86765295]\n",
            "480 0.008639648 [1.0601416] [0.8828695]\n",
            "500 0.0075450735 [1.0562029] [0.89708966]\n",
            "520 0.006589149 [1.0525221] [0.9103784]\n",
            "540 0.0057543493 [1.0490823] [0.922797]\n",
            "560 0.0050253137 [1.0458678] [0.9344023]\n",
            "580 0.004388637 [1.042864] [0.9452474]\n",
            "600 0.0038326369 [1.0400567] [0.95538217]\n",
            "620 0.003347084 [1.0374334] [0.9648533]\n",
            "640 0.002923012 [1.0349818] [0.9737042]\n",
            "660 0.0025526907 [1.032691] [0.9819754]\n",
            "680 0.002229289 [1.03055] [0.98970485]\n",
            "700 0.0019468609 [1.0285492] [0.99692816]\n",
            "720 0.001700213 [1.0266796] [1.0036782]\n",
            "740 0.0014848064 [1.0249323] [1.0099865]\n",
            "760 0.001296689 [1.0232995] [1.0158817]\n",
            "780 0.0011323963 [1.0217735] [1.0213908]\n",
            "800 0.0009889391 [1.0203476] [1.0265388]\n",
            "820 0.00086365064 [1.019015] [1.0313498]\n",
            "840 0.0007542305 [1.0177697] [1.0358456]\n",
            "860 0.00065867265 [1.016606] [1.0400472]\n",
            "880 0.0005752294 [1.0155183] [1.0439736]\n",
            "900 0.0005023497 [1.014502] [1.0476428]\n",
            "920 0.0004387056 [1.0135523] [1.0510716]\n",
            "940 0.00038312358 [1.0126648] [1.054276]\n",
            "960 0.00033458666 [1.0118355] [1.0572704]\n",
            "980 0.00029219812 [1.0110602] [1.0600688]\n",
            "1000 0.00025518023 [1.010336] [1.0626838]\n",
            "1020 0.00022284788 [1.0096589] [1.0651277]\n",
            "1040 0.00019461496 [1.0090264] [1.0674115]\n",
            "1060 0.00016995703 [1.0084352] [1.069546]\n",
            "1080 0.00014842747 [1.0078828] [1.0715405]\n",
            "1100 0.00012962114 [1.0073665] [1.0734043]\n",
            "1120 0.00011319683 [1.006884] [1.0751462]\n",
            "1140 9.885493e-05 [1.0064331] [1.076774]\n",
            "1160 8.632928e-05 [1.0060118] [1.0782951]\n",
            "1180 7.53961e-05 [1.0056182] [1.0797162]\n",
            "1200 6.5843924e-05 [1.0052503] [1.0810444]\n",
            "1220 5.7501755e-05 [1.0049064] [1.0822859]\n",
            "1240 5.0216076e-05 [1.0045851] [1.083446]\n",
            "1260 4.385398e-05 [1.0042849] [1.0845301]\n",
            "1280 3.8298713e-05 [1.0040044] [1.0855432]\n",
            "1300 3.344701e-05 [1.0037421] [1.0864898]\n",
            "1320 2.920971e-05 [1.003497] [1.0873746]\n",
            "1340 2.5510753e-05 [1.003268] [1.0882014]\n",
            "1360 2.2278145e-05 [1.003054] [1.0889741]\n",
            "1380 1.9457799e-05 [1.0028541] [1.0896958]\n",
            "1400 1.699104e-05 [1.0026672] [1.0903707]\n",
            "1420 1.4839051e-05 [1.0024925] [1.0910013]\n",
            "1440 1.2958926e-05 [1.0023292] [1.0915906]\n",
            "1460 1.1316969e-05 [1.0021768] [1.0921413]\n",
            "1480 9.883153e-06 [1.0020342] [1.0926559]\n",
            "1500 8.630759e-06 [1.001901] [1.0931369]\n",
            "1520 7.5382004e-06 [1.0017765] [1.0935863]\n",
            "1540 6.5837403e-06 [1.0016602] [1.0940063]\n",
            "1560 5.749555e-06 [1.0015515] [1.0943987]\n",
            "1580 5.0210137e-06 [1.0014498] [1.0947657]\n",
            "1600 4.384674e-06 [1.0013548] [1.0951085]\n",
            "1620 3.8290423e-06 [1.0012662] [1.0954287]\n",
            "1640 3.344112e-06 [1.0011833] [1.095728]\n",
            "1660 2.9206535e-06 [1.0011058] [1.0960077]\n",
            "1680 2.5503257e-06 [1.0010334] [1.0962691]\n",
            "1700 2.2272725e-06 [1.0009656] [1.0965135]\n",
            "1720 1.94504e-06 [1.0009024] [1.096742]\n",
            "1740 1.6987411e-06 [1.0008434] [1.0969553]\n",
            "1760 1.4837309e-06 [1.0007881] [1.0971545]\n",
            "1780 1.2958783e-06 [1.0007366] [1.0973408]\n",
            "1800 1.131709e-06 [1.0006883] [1.0975149]\n",
            "1820 9.882866e-07 [1.0006433] [1.0976776]\n",
            "1840 8.6325116e-07 [1.0006013] [1.0978296]\n",
            "1860 7.540087e-07 [1.000562] [1.0979716]\n",
            "1880 6.585851e-07 [1.0005252] [1.0981042]\n",
            "1900 5.7517974e-07 [1.0004908] [1.0982282]\n",
            "1920 5.0238486e-07 [1.0004587] [1.0983442]\n",
            "1940 4.387648e-07 [1.0004287] [1.0984526]\n",
            "1960 3.8320906e-07 [1.0004005] [1.0985538]\n",
            "1980 3.3467563e-07 [1.0003743] [1.0986484]\n",
            "2000 2.9246758e-07 [1.00035] [1.0987366]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "va345Uk8gVzp"
      },
      "source": [
        "* X, Y를 미리 정하지 않고 placeholder를 사용하여 실행시킬 때 feed_dict로 넘겨준다.\n",
        "  * 나머지 과정은 이전과 동일하다. \n",
        "\n",
        "\n",
        "* 학습이 진행될수록 예상했던대로 W=1, b=1.1에 가까운 값이 나왔다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wyCqAvj2hf0Q"
      },
      "source": [
        "**모델 테스트하기**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YYA1TRXUgOok",
        "outputId": "a14229e2-3f1c-4e20-d6d7-1af3c7dfd1b2"
      },
      "source": [
        "# Testing our model\n",
        "print(sess.run(hypothesis, feed_dict={X:[5]}))\n",
        "print(sess.run(hypothesis, feed_dict={X:[2.5]}))\n",
        "print(sess.run(hypothesis, feed_dict={X:[1.5, 3.5]}))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[6.1004868]\n",
            "[3.5996118]\n",
            "[2.5992618 4.5999618]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KOFLJcQ1heZ3"
      },
      "source": [
        "주어진 X에 1.1을 더한 값과 유사한 결과를 나타낸다. "
      ]
    }
  ]
}